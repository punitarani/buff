{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fact Rank"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af95eaf30e35475c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:35.347262100Z",
     "start_time": "2024-03-14T23:51:33.311656200Z"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "from config import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chroma_db_path = DATA_DIR.joinpath(\"chroma\").resolve()\n",
    "\n",
    "chroma = chromadb.PersistentClient(path=str(chroma_db_path))\n",
    "vecstore = chroma.get_or_create_collection(\"factrank\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:35.856624100Z",
     "start_time": "2024-03-14T23:51:35.335392100Z"
    }
   },
   "id": "f66e2a71b7907575",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f1a3ab43de79999"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from buff.openalex import Work\n",
    "from buff.openalex.download import get_paper_text\n",
    "from buff.llm.utils import get_token_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:38.687809100Z",
     "start_time": "2024-03-14T23:51:35.825771900Z"
    }
   },
   "id": "49063fa7dc076e8e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main paper: https://openalex.org/W2994792393\n",
      "Citations: 39\n",
      "References: 23\n"
     ]
    }
   ],
   "source": [
    "with open(\"works.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    FOCUS_PAPER = json.load(file).get(\"id\") \n",
    "    \n",
    "with open(\"citations.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    CITATIONS = list(json.load(file).keys())\n",
    "    \n",
    "with open(\"references.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    REFERENCES = list(json.load(file).keys())\n",
    "    \n",
    "print(\"Main paper:\", FOCUS_PAPER)\n",
    "print(\"Citations:\", len(CITATIONS))\n",
    "print(\"References:\", len(REFERENCES))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:38.770869Z",
     "start_time": "2024-03-14T23:51:38.698082Z"
    }
   },
   "id": "61e9c1438261c9e0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works: 63\n"
     ]
    }
   ],
   "source": [
    "WORKS = {\n",
    "    work_id: await Work(work_id).data\n",
    "    for work_id in [FOCUS_PAPER] + CITATIONS + REFERENCES\n",
    "}\n",
    "print(\"Works:\", len(WORKS))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:41.127117500Z",
     "start_time": "2024-03-14T23:51:38.721235700Z"
    }
   },
   "id": "df6c81594456b774",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: 63\n"
     ]
    }
   ],
   "source": [
    "TEXTS = {\n",
    "    work_id: await get_paper_text(work)\n",
    "    for work_id, work in WORKS.items()\n",
    "}\n",
    "print(\"Texts:\", len(TEXTS))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:51:57.961934800Z",
     "start_time": "2024-03-14T23:51:41.090550900Z"
    }
   },
   "id": "a590680059c94b46",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process and Prepare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683ba6475e0e8547"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from buff.llm.split import split_text\n",
    "# \n",
    "# TEXT_CHUNKS = {\n",
    "#     work_id: split_text(text)\n",
    "#     for work_id, text in TEXTS.items()\n",
    "# }\n",
    "# \n",
    "# # Save the chunks\n",
    "# with open(\"chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(TEXT_CHUNKS, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:53:36.814554300Z",
     "start_time": "2024-03-14T23:51:57.964496500Z"
    }
   },
   "id": "48ba9dc253f43b8",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the chunks\n",
    "with open(\"chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    TEXT_CHUNKS = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:53:36.919277900Z",
     "start_time": "2024-03-14T23:53:36.792304700Z"
    }
   },
   "id": "9eb4ecd9b312a0bd",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 2500\n"
     ]
    }
   ],
   "source": [
    "print(\"Chunks:\", sum(len(chunks) for chunks in TEXT_CHUNKS.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:53:36.922701300Z",
     "start_time": "2024-03-14T23:53:36.867379200Z"
    }
   },
   "id": "ff1c30552f4eebc9",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Embed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fdd6bb49e000358"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from buff.llm.embed import embed_texts\n",
    "# \n",
    "# EMBEDDINGS = {\n",
    "#     work_id: await embed_texts(chunks)\n",
    "#     for work_id, chunks in TEXT_CHUNKS.items()\n",
    "# }\n",
    "# \n",
    "# # Save the embeddings\n",
    "# with open(\"embeddings.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(EMBEDDINGS, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:55:16.501469900Z",
     "start_time": "2024-03-14T23:53:36.883837300Z"
    }
   },
   "id": "4bdb4dcfc3812380",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the embeddings\n",
    "with open(\"embeddings.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    EMBEDDINGS = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:55:22.170886400Z",
     "start_time": "2024-03-14T23:55:16.504031900Z"
    }
   },
   "id": "f79f7ae72bea3f73",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 2500\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings:\", sum(len(embeds) for embeds in EMBEDDINGS.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:55:22.208252800Z",
     "start_time": "2024-03-14T23:55:22.172400200Z"
    }
   },
   "id": "c575a63944f04c38",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Store"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26793e322579532e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 2500 documents.\n",
      "Embeddings stored\n"
     ]
    }
   ],
   "source": [
    "# from buff.llm.models import Document, DocumentMetadata\n",
    "# \n",
    "# # Build the documents\n",
    "# DOCUMENTS = {\n",
    "#     work_id: [\n",
    "#         Document(\n",
    "#             metadata=DocumentMetadata(\n",
    "#                 index=i,\n",
    "#                 work_id=work_id,\n",
    "#                 doi=str(WORKS[work_id].doi),\n",
    "#                 text=TEXT_CHUNKS[work_id][i]\n",
    "#             ),\n",
    "#             id=f\"{work_id}-{i}\",\n",
    "#             values=embed\n",
    "#         )\n",
    "#         for i, embed in enumerate(embeds)\n",
    "#     ]\n",
    "#     for work_id, embeds in EMBEDDINGS.items()\n",
    "# }\n",
    "# \n",
    "# # Create the following lists of data from the documents\n",
    "# TEXT_CHUNK_IDS = [doc.id for docs in DOCUMENTS.values() for doc in docs]\n",
    "# TEXT_CHUNK_EMBEDDINGS = [doc.values for docs in DOCUMENTS.values() for doc in docs]\n",
    "# TEXT_CHUNK_METADATA = [doc.metadata.model_dump(mode=\"json\") for docs in DOCUMENTS.values() for doc in docs]\n",
    "# print(f\"Total: {len(TEXT_CHUNK_IDS)} documents.\")\n",
    "# if not len(TEXT_CHUNK_EMBEDDINGS) == len(TEXT_CHUNK_METADATA) == len(TEXT_CHUNK_IDS):\n",
    "#     raise ValueError(\"Invalid data\")\n",
    "# \n",
    "# # Store the embeddings\n",
    "# vecstore.add(\n",
    "#     ids=TEXT_CHUNK_IDS,\n",
    "#     embeddings=TEXT_CHUNK_EMBEDDINGS,\n",
    "#     metadatas=TEXT_CHUNK_METADATA\n",
    "# )\n",
    "# print(\"Embeddings stored\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T23:57:03.358618100Z",
     "start_time": "2024-03-14T23:56:56.026756800Z"
    }
   },
   "id": "8129546dcba3a64d",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02ceb34d9b35ced"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks per work: 11 - 39.682539682539684 - 81\n",
      "Tokens per chunk: 25 - 526.578 - 929\n"
     ]
    }
   ],
   "source": [
    "# Print the min-median-max number of chunks per work\n",
    "print(\"Chunks per work:\", min(len(chunks) for chunks in TEXT_CHUNKS.values()), \"-\", sum(len(chunks) for chunks in TEXT_CHUNKS.values()) / len(TEXT_CHUNKS), \"-\", max(len(chunks) for chunks in TEXT_CHUNKS.values()))\n",
    "\n",
    "# Print the min-median-max number of tokens per chunk\n",
    "print(\"Tokens per chunk:\", min(get_token_count(chunk) for chunks in TEXT_CHUNKS.values() for chunk in chunks), \"-\", sum(get_token_count(chunk) for chunks in TEXT_CHUNKS.values() for chunk in chunks) / sum(len(chunks) for chunks in TEXT_CHUNKS.values()), \"-\", max(get_token_count(chunk) for chunks in TEXT_CHUNKS.values() for chunk in chunks))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T00:03:36.176251600Z",
     "start_time": "2024-03-15T00:03:26.773210300Z"
    }
   },
   "id": "c42bfa0afa9f2bed",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
